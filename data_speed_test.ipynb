{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bokeh\n",
    "import sqlalchemy as sa\n",
    "import time\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/5194057/better-way-to-convert-file-sizes-in-python\n",
    "\n",
    "import math\n",
    "\n",
    "def convert_size(size_bytes):\n",
    "   if size_bytes == 0:\n",
    "       return \"0B\"\n",
    "   size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "   i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "   p = math.pow(1024, i)\n",
    "   s = round(size_bytes / p, 2)\n",
    "   return \"%s %s\" % (s, size_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = [\"csv\", \"feather\", \"pickle\", \"h5\", \"parquet\", \"db\"]\n",
    "\n",
    "# data_type = {'CSV': 'csv', 'FEATHER': \"feather\", \"PICKLE\": \"pickle\", \"H5\": \"h5\", 'PARQUET': \"parquet\", \"DB1\": \"db\"}\n",
    "class DataBase:\n",
    "    def __init__(self, df=None, ext=\"csv\", fname=\"df\") -> None:\n",
    "        self.df = df\n",
    "        self.ext = ext\n",
    "        self.fname = \"df\"\n",
    "        self.location = Path(f\"data/output/{self.fname}.{ext}\")\n",
    "        self.write_time = -1\n",
    "        self.read_time = -1\n",
    "        self._size = -1\n",
    "        self.conn = None\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return round(self.location.stat().st_size / 1024, 2)\n",
    "\n",
    "    def write(self):\n",
    "        if self.ext == \"csv\":\n",
    "            start = time.time()\n",
    "            self.df.to_csv(str(self.location))\n",
    "            self.write_time = time.time() - start\n",
    "\n",
    "        elif self.ext == \"feather\":\n",
    "            start = time.time()\n",
    "            self.df.to_feather(str(self.location))\n",
    "            self.write_time = time.time() - start\n",
    "\n",
    "        elif self.ext == \"pickle\":\n",
    "            start = time.time()\n",
    "            self.df.to_pickle(str(self.location))\n",
    "            self.write_time = time.time() - start\n",
    "\n",
    "        elif self.ext == \"h5\":\n",
    "            start = time.time()\n",
    "            self.df.to_hdf(str(self.location), key=\"df\", mode=\"w\")\n",
    "            self.write_time = time.time() - start\n",
    "\n",
    "        elif self.ext == \"parquet\":\n",
    "            start = time.time()\n",
    "            self.df.to_parquet(str(self.location))\n",
    "            self.write_time = time.time() - start\n",
    "\n",
    "        elif self.ext == \"db\":\n",
    "            # sql\n",
    "            # conn = sa.create_engine('postgresql://127.0.0.1/pierre', echo=False)\n",
    "            # https://stackoverflow.com/questions/58896928/how-to-connect-to-sqlite-from-sqlalchemy\n",
    "            self.conn = sa.create_engine(f\"sqlite:///{str(self.location)}\", echo=False)\n",
    "            start = time.time()\n",
    "            self.df.to_sql(\"transactions\", self.conn, if_exists=\"replace\")\n",
    "            self.write_time = time.time() - start\n",
    "\n",
    "    def read(self):\n",
    "        if self.ext == \"csv\":\n",
    "            start = time.time()\n",
    "            self.df = pd.read_csv(str(self.location))\n",
    "            self.read_time = time.time() - start\n",
    "\n",
    "        elif self.ext == \"feather\":\n",
    "            start = time.time()\n",
    "            self.df = pd.read_feather(str(self.location))\n",
    "            self.read_time = time.time() - start\n",
    "\n",
    "        elif self.ext == \"pickle\":\n",
    "            start = time.time()\n",
    "            self.df = pd.read_pickle(str(self.location))\n",
    "            self.read_time = time.time() - start\n",
    "\n",
    "        elif self.ext == \"h5\":\n",
    "            start = time.time()\n",
    "            self.df = pd.read_hdf(str(self.location), \"df\")\n",
    "            self.read_time = time.time() - start\n",
    "\n",
    "        elif self.ext == \"parquet\":\n",
    "            start = time.time()\n",
    "            self.df = pd.read_parquet(str(self.location))\n",
    "            self.read_time = time.time() - start\n",
    "\n",
    "        elif self.ext == \"db\":\n",
    "            start = time.time()\n",
    "            self.df = pd.read_sql(\"SELECT * from transactions\", self.conn)\n",
    "            # with tempfile.TemporaryFile(mode='w+') as tmpfile:\n",
    "            # # with open('temp_file.csv', 'w+') as tmpfile:\n",
    "            #     copy_sql = \"COPY (select * from transactions) TO STDOUT WITH CSV HEADER\"\n",
    "            #     copy_sql = \"select * from transactions\"\n",
    "            #     # conn = self.conn.raw_connection()\n",
    "            #     # cur = conn.cursor()\n",
    "            #     tmp_csv = self.conn.connect().execute(sa.text(copy_sql))\n",
    "            #     print(tmp_csv.keys())\n",
    "            #     # print(tmp_csv)\n",
    "            #     outcsv = csv.writer(tmpfile)\n",
    "            #     outcsv.writerow(tmp_csv.keys())\n",
    "            #     outcsv.writerows(tmp_csv)\n",
    "            #     # cur.copy_export(copy_sql, tmpfile)\n",
    "            #     # tmpfile.flush()\n",
    "            #     # tmpfile.seek(0)\n",
    "            #     # tmpfile.write(\"temp data\")\n",
    "            #     tmpfile.flush()\n",
    "            #     tmpfile.seek(0)\n",
    "            #     # print(tmpfile.readlines())\n",
    "            #     self.df = pd.read_csv(tmpfile)\n",
    "            #     # cur.close()\n",
    "            #     # conn.close()\n",
    "            self.read_time = time.time() - start\n",
    "            # if self.conn:\n",
    "            #     self.conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(r'data/input/example_transaction.csv',)\n",
    "df  = pd.read_csv(r'data/input/airline_dataset.csv')\n",
    "# df  = pd.read_csv(r'data/input/credit_card_transactions.csv')\n",
    "\n",
    "dbs = {}\n",
    "for dtype in data_type:\n",
    "    tmp_db = DataBase(df, ext=dtype)\n",
    "\n",
    "    tmp_db.write()\n",
    "\n",
    "    tmp_db.read()\n",
    "\n",
    "    dbs[dtype] = tmp_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write times: \n",
      "  Time to write csv: 0.95506 seconds\n",
      "  Time to write feather: 0.13116 seconds\n",
      "  Time to write pickle: 0.15820 seconds\n",
      "  Time to write h5: 0.33273 seconds\n",
      "  Time to write parquet: 0.35640 seconds\n",
      "  Time to write db: 3.27293 seconds\n",
      "The fastest file format for writing is feather\n",
      "The slowest file format for writing is db\n",
      "\n",
      "read times: \n",
      "  Time to read csv: 0.52417 seconds\n",
      "  Time to read feather: 0.16711 seconds\n",
      "  Time to read pickle: 0.13914 seconds\n",
      "  Time to read h5: 0.32019 seconds\n",
      "  Time to read parquet: 0.15522 seconds\n",
      "  Time to read db: 1.48319 seconds\n",
      "The fastest file format for reading is pickle\n",
      "The slowest file format for reading is db\n",
      "\n",
      "size: \n",
      "  csv size: 12969.16 KB\n",
      "  feather size: 11615.57 KB\n",
      "  pickle size: 9784.51 KB\n",
      "  h5 size: 10501.19 KB\n",
      "  parquet size: 4270.36 KB\n",
      "  db size: 14840.00 KB\n",
      "The smallest file format is parquet\n",
      "The largest file format is db\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('write times: ')\n",
    "for dtype in data_type:\n",
    "    print(f'  Time to write {dtype}: {dbs[dtype].write_time:.5f} seconds')\n",
    "\n",
    "fastest_write = min(dbs, key=lambda x: dbs[x].write_time)\n",
    "slowest_write = max(dbs, key=lambda x: dbs[x].write_time)\n",
    "print(f'The fastest file format for writing is {fastest_write}')\n",
    "print(f'The slowest file format for writing is {slowest_write}')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('read times: ')\n",
    "for dtype in data_type:\n",
    "    print(f'  Time to read {dtype}: {dbs[dtype].read_time:.5f} seconds')\n",
    "    # print(dbs[dtype].df.head)\n",
    "fastest_read = min(dbs, key=lambda x: dbs[x].read_time)\n",
    "slowest_read = max(dbs, key=lambda x: dbs[x].read_time)\n",
    "print(f'The fastest file format for reading is {fastest_read}')\n",
    "print(f'The slowest file format for reading is {slowest_read}')\n",
    "print('')\n",
    "\n",
    "print('size: ')\n",
    "for dtype in data_type:\n",
    "    print(f'  {dtype} size: {dbs[dtype].size:.2f} KB')\n",
    "smallest = min(dbs, key=lambda x: dbs[x].size)\n",
    "largest = max(dbs, key=lambda x: dbs[x].size)\n",
    "print(f'The smallest file format is {smallest}')\n",
    "print(f'The largest file format is {largest}')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastest_format_reading = min(reading_times, key=reading_times.get)\n",
    "slowest_format_reading = max(reading_times, key=reading_times.get)\n",
    "print(f'The fastest file format for reading is {fastest_format_reading}')\n",
    "print(f'The slowest file format for reading is {slowest_format_reading}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
